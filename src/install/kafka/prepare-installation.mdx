---
headingText: Prepare for the installation
componentType: default
---

Kafka is a complex piece of software that is built as a distributed system. For this reason, you need to ensure that the integration can contact all the required hosts and services so the data is collected correctly.

<CollapserGroup>
  <Collapser
    id="autodiscovery"
    title="Autodiscovery"
  >
    Given the distributed nature of Kafka, the actual number and list of brokers is usually not fixed by the configuration, and it's instead quite dynamic. For this reason, the Kafka integration offers two mechanisms to perform automatic discovery of the list of brokers in the cluster: Bootstrap and Zookeeper. The mechanism you use depends on the setup of the Kafka cluster being monitored.

    ### Bootstrap

    With the bootstrap mechanism, the integration uses a bootstrap broker to perform the autodiscovery. This is a broker whose address is well known and that will be asked for any other brokers it's aware of. The integration needs to be able to contact this broker in the address provided in the `bootstrap_broker_host` parameter for bootstrap discovery to work.

    ### Zookeeper

    Alternatively, the Kafka integration can also talk to a Zookeeper server in order to obtain the list of brokers. To do this,  you need to provide the integration with the following:

    * The list of Zookeeper hosts, `zookeeper_hosts`, to contact.
    * The proper authentication secrets to connect with the hosts.

    Together with the list of brokers it knows about, Zookeeper will also advertise which connection mechanisms are supported by each broker.

    You can configure the Kafka integration to try directly with one of these mechanisms with the `preferred_listener` parameter. If this parameter is not provided, the integration will try to contact the brokers with all the advertised configurations until one of them succeeds.

    <Callout variant="tip">
      The integration will use Zookeeper only for discovering brokers and will not retrieve metrics from it.
    </Callout>
  </Collapser>

  <Collapser
    id="topic-listing"
    title="Topic listing"
  >
    To correctly list the topics processed by the brokers, the integration needs to contact brokers over the Kafka protocol. Depending on how the brokers are configured, this might require setting up SSL and SASL to match the broker configuration. The topics must have `DESCRIBE` access.
  </Collapser>

  <Collapser
    id="broker-monitoring"
    title="Broker monitoring (JMX)"
  >
    The Kafka integration queries JMX, a standard Java extension for exchanging metrics in Java applications. JMX is not enabled by default in Kafka brokers, and you need to enable it for metrics collection to work properly. JMX requires RMI to be enabled, and the RMI port needs to be set to the same port as JMX.

    You can configure JMX to use username and password authentication, as well as SSL. If such features have been enabled in the broker's JMX settings, you need to configure the integration accordingly.

    If autodiscovery is set to bootstrap, the JMX settings defined for the bootstrap broker will be applied for all other discovered brokers, so the port and other settings should be the same on all the brokers.

    <Callout variant="important">
      We don't recommend enabling anonymous and unencrypted JMX/RMI access on public or untrusted network segments because this poses a big security risk.
    </Callout>
  </Collapser>

  <Collapser
    id="consumer-offset"
    title="Consumer offset"
  >
    You can get the offsets of consumers and consumer groups, as well as the lag. Use a [`KafkaOffsetSample`](/docs/infrastructure/host-integrations/host-integrations-list/kafka/kafka-config/#KafkaOffsetSample-collection) with the `CONSUMER_OFFSET=true` flag. Note that it must be in a separate instance because when this flag is activated, the instance will not collect other samples.
  </Collapser>

  <Collapser
    id="producer"
    title="Producer and consumer monitoring (JMX)"
  >
    You can also monitor producers and consumers written in Java to get more specific metadata through the same mechanism (JMX). This will generate `KafkaConsumerSamples` and `KafkaProducerSamples`. JMX needs to be enabled and configured on those applications where it is not enabled by default.

    Non-Java producers and consumers don't support JMX and are therefore not supported by the Kafka integration.
  </Collapser>
</CollapserGroup>

