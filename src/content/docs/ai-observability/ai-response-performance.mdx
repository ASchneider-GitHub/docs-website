---
title: 'Explore AI data in New Relic'
metaDescription: 'AI monitoring lets you observe the AI-layer of your tech stack, giving you a holistic overview of the health and performance of your AI-powered app.'
freshnessValidatedDate: never
---

import apmAIEntitiesPage from 'images/apm_screenshot-crop_AI-entities-page.webp'

import apmFindAiResponsesFromApm from 'images/apm_screenshot-crop_find-ai-responses-from-apm.webp'

import apmAiResponsesDefaultView from 'images/apm_screenshot-crop_ai-responses-default-view.webp'

import apmResponseTable from 'images/apm_screenshot-crop_response-table.webp'

import apmAdjustTable from 'images/apm_screenshot-crop_adjust-response-table.gif'

With AI monitoring enabled, your agent can recognize and capture performance metrics and trace data about the AI-layer of your apps. From **[one.newrelic.com](https://one.newrelic.com)**, go to **All Capabilities** and choose **AI Monitoring** to see a table of all your AI-powered apps. From the AI Entities page, you have three entry points into viewing and analyzing your data:

<img
    title="AI Entities page"
    alt="A screenshot of the first page you see when you click AI Monitoring. View aggregated data, compare your AI models, or create drop filters."
    src={apmAIEntitiesPage}
/>
<figcaption>
    Start exploring your AI data from the AI entities page: Go to **[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI Monitoring**, then choose one of our entry points to explore your data.
</figcaption>

* **AI Entities**: Check your app's performance at a glance with data about response time, throughput, and error rate. Choose an AI-powered app to view AI data scoped to that app.
* **AI Responses**: Overview aggregated data about all your AI entities. Check how many tokens all your AI apps use together, or monitor how your AI apps are performing in general. 
* **Compare Models**: Compare token usage, response time, and error rate between different models. If you're conducting A/B tests, get all the information you need to make decisions about your AI-powered app.

<Tabs>
	<TabsBar>
        <TabsBarItem id="app-scoped">
            View AI data scoped by application
        </TabsBarItem>
        <TabsBarItem id="aggregated-data">
            Overview aggregated data about your AI apps
        </TabsBarItem>
        <TabsBarItem id="compare-models">
            Compare your models 
        </TabsBarItem>
    </TabsBar>

    <TabsPages>
        <TabsPageItem id="entity-scoped">

Scoping your data by AI entity takes you to the APM summary page for the app. To find data about your AI data, choose **AI Responses**: 

<img
    title="Find entity-scoped AI Responses page"
    alt="A screenshot of the APM summary page. A green arrow highlights where to find data about the AI-layer of your app"
    src={apmFindAiResponsesFromApm}
/>
<figcaption>
    To find data about the AI-layer of your app, click **AI Responses** from the APM summary page. 
</figcaption>

Similar to the page that aggregates AI metrics across all your AI entities, the scoped AI responses page limits context to one app. This allows you to evaluate the performance of your app in general, then dig deeper into its AI layer. You can view app-specific data about token usage, total responses, and how these metrics trend over time. 

<img
    title="AI monitoring response page"
    alt="A screenshot that shows the default view for AI responses "
    src={apmAiResponsesDefaultView}
    />

<figcaption>
    To access your AI data: Go to **[one.newrelic.com](https://one.newrelic.com) > All capabilities > AI Monitoring**, then choose your AI entity.
</figcaption>

Like our other APM pages, the AI responses page offers functionalities that let you filter and explore your data: 

* **Query your responses with the filter bar.** You can update this page with querying that further scope your metrics by attributes like errors, vendors, or text strings.
* ** Track changes over time with time series graphs.** Adjust the graphs to display a time series for feedback type, response time, or tokens per response. Determine whether negative feedback correlates with higher or lower token usage, or if slower response times occur when your total responses go up. 
* **Overview user prompts and AI responses with the responses table.** The response table is your entry point into viewing trace-level details about how your AI assistant responded to a prompt. Get a sense for number of completions for responses, feedback trends from your end user, or preview your AI responses in aggregate.  

### Dig into your AI responses 

Your AI response table further scopes your data by responses, showing you details about individual prompt/response interactions. 

<img
    title="App-scoped AI responses table"
    alt="A screenshot that shows response table"
    src={apmResponseTable}
/>

You can adjust the kinds of information in the table by clicking the cog icon in the upper right. For example, maybe you're at a development stage where the cost of a particular app is more important than how end users respond to an AI's response. Maybe you're concerned about end user feedback in a separate app. This functionality gives you flexibility when prioritizing the kinds of data you want to monitor across your various entities.

<img
    title="App-scoped AI responses table"
    alt="A screenshot that shows response table"
    src={apmAdjustTable}
/>

The **Responses** table is an entry point into viewing trace data about an individual response. You can use this to better understand how your app generates responses, or to dig deeper into performance outliers. For example, you may want to look at the trace view to get a sense for what processes led to a particularly low cost response, or maybe you want to understand what led to negative feedback from a high token response.

### View traces for an individual response



        </TabsPageItem>
        <TabsPageItem id="aggregated-AI">
            find use case
        </TabsPageItem>
        <TabsPageItem id="compare-models">
            add content
        </TabsPageItem>
    </TabsPages>
</Tabs>

## What's next? [#whats-next]

