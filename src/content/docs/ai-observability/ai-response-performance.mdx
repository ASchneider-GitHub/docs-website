---
title: 'Explore AI data in New Relic'
metaDescription: 'AI monitoring lets you observe the AI-layer of your tech stack, giving you a holistic overview of the health and performance of your AI-powered app.'
freshnessValidatedDate: never
---

import apmAIEntitiesPage from 'images/apm_screenshot-crop_AI-entities-page.webp'

import apmFindAiResponsesFromApm from 'images/apm_screenshot-crop_find-ai-responses-from-apm.webp'

import apmAiResponsesDefaultView from 'images/apm_screenshot-crop_ai-responses-default-view.webp'

import apmResponseTable from 'images/apm_screenshot-crop_response-table.webp'

import apmAdjustTable from 'images/apm_screenshot-crop_adjust-response-table.gif'

With AI monitoring enabled, your agent can recognize and capture performance metrics and trace data about the AI-layer of your apps. From **[one.newrelic.com](https://one.newrelic.com)**, go to **All Capabilities** and choose **AI Monitoring**. 

## Start with AI Entities [#ai-entities] 

to see a table of all your AI-powered apps. From the AI Entities page, you have three entry points into viewing and analyzing your data:

<img
    title="AI Entities page"
    alt="A screenshot of the first page you see when you click AI Monitoring. View aggregated data, compare your AI models, or create drop filters."
    src={apmAIEntitiesPage}
/>
<figcaption>
    Start exploring your AI data from the AI entities page: Go to **[one.newrelic.com](https://one.newrelic.com) > All Capabilities > AI Monitoring**, then choose one of our entry points to explore your data.
</figcaption>

* **AI Entities**: Check your app's performance at a glance with data about response time, throughput, and error rate. Choose an AI-powered app to view AI data scoped to that app.
* **AI Responses**: Overview aggregated data about all your AI entities. Check how many tokens all your AI apps use together, or monitor how your AI apps are performing in general. 
* **Compare Models**: Compare token usage, response time, and error rate between different models. If you're conducting A/B tests, get all the information you need to make decisions about your AI-powered app.

<Tabs>
	<TabsBar>
        <TabsBarItem id="app-scoped">
            View AI data scoped by application
        </TabsBarItem>
        <TabsBarItem id="aggregated-data">
            Overview aggregated data about your AI apps
        </TabsBarItem>
        <TabsBarItem id="compare-models">
            Compare your models 
        </TabsBarItem>
    </TabsBar>

    <TabsPages>
        <TabsPageItem id="entity-scoped">

When you choose an AI entity, you'll be taken to the APM summary page. This page contains summary tiles and time series graphs that measure the health of your entire app. To find your AI data, choose **AI Responses** in the left nav: 

<img
    title="Find entity-scoped AI Responses page"
    alt="A screenshot of the APM summary page. A green arrow highlights where to find data about the AI-layer of your app"
    src={apmFindAiResponsesFromApm}
/>
<figcaption>
    To find data about the AI-layer of your app, click **AI Responses** from the APM summary page. 
</figcaption>

Like the APM summary page, the **AI Responses** page contains tiles, time series graphs, and a table of data collected by AI monitoring. Each area of the summary page is a different vantage point that can help you identify possible anomalies. 

<img
    title="AI monitoring response page"
    alt="A screenshot that shows the default view for AI responses "
    src={apmAiResponsesDefaultView}
    />

<figcaption>
    To access your AI data: Go to **[one.newrelic.com](https://one.newrelic.com) > All capabilities > AI Monitoring**, then choose your AI entity.
</figcaption>

Like other APM functionalities, you can use the filter bar to scope your data by attributes like errors, vendors, or text strings. Some possible starter queries might be:

* 
*
*

### Track total responses, average response time, and token usage  

* ** Track changes over time with time series graphs.** Adjust the graphs to display a time series for feedback type, response time, or tokens per response. Determine whether negative feedback correlates with higher or lower token usage, or if slower response times occur when your total responses go up. 
* **Overview user prompts and AI responses with the responses table.** The response table is your entry point into viewing trace-level details about how your AI assistant responded to a prompt. Get a sense for number of completions for responses, feedback trends from your end user, or preview your AI responses in aggregate.  

### Dig into your AI responses 

Your AI response table further scopes your data by responses, showing you details about individual prompt/response interactions. 

<img
    title="App-scoped AI responses table"
    alt="A screenshot that shows response table"
    src={apmResponseTable}
/>

You can adjust the kinds of information in the table by clicking the cog icon in the upper right. For example, maybe you're at a development stage where the cost of a particular app is more important than how end users respond to an AI's response. Maybe you're concerned about end user feedback in a separate app. This functionality gives you flexibility when prioritizing the kinds of data you want to monitor across your various entities.

<img
    title="App-scoped AI responses table"
    alt="A screenshot that shows response table"
    src={apmAdjustTable}
/>

The **Responses** table is an entry point into viewing trace data about an individual response. You can use this to better understand how your app generates responses, or to dig deeper into performance outliers. For example, you may want to look at the trace view to get a sense for what processes led to a particularly low cost response, or maybe you want to understand what led to negative feedback from a high token response.

### View traces for an individual response



        </TabsPageItem>
        <TabsPageItem id="aggregated-AI">
            find use case
        </TabsPageItem>
        <TabsPageItem id="compare-models">
            add content
        </TabsPageItem>
    </TabsPages>
</Tabs>

## What's next? [#whats-next]

