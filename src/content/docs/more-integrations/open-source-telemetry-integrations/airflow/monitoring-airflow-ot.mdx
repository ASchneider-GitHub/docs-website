---
title: Monitor Airflow with OpenTelemetry and New Relic 
tags:
  - Integrations
  - Open source telemetry integrations
  - OpenTelemetry
  - Airflow
  - Quickstart
metaDescription: Here is a simple example to setup Airflow OpenTelemetry metrics to send data to New Relic.
redirects:
  - /docs/more-integrations/open-source-telemetry-integrations/opentelemetry/airflow/monitoring-airflow-ot
---

import opentelemetryAirflow01 from 'images/opentelemetry_screenshot_airflow_01.webp'
import opentelemetryAirflow02 from 'images/opentelemetry_screenshot_airflow_02.webp'

Monitor Airflow with [OpenTelemetry Metrics](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/metrics.html#setup-opentelemetry) by visualizing tasks, operators, and DAG executions as metrics.

<img
  title="Screenshot showing sample Airflow DAG runs in New Relic"
  alt="Screenshot showing sample Airflow DAG runs in New Relic"
  src={opentelemetryAirflow01}
/>

## Prerequisites [#prerequisites]

You need to first install the Airflow package with OpenTelemetry using the `otel` extra. This can be done in one of several ways, depending on how you deploy Airflow:

### Installing from PyPi [#install-pypi]

1. Follow the installation instructions from [Airflow's Documentation](https://airflow.apache.org/docs/apache-airflow/stable/installation/installing-from-pypi.html).
2. When installing with pip, add the `otel` extra to the command.
  a. eg. `pip install "apache-airflow[otel]"`

### Installing from Docker [#install-docker]

1. Setup the [Airflow Docker image](https://airflow.apache.org/docs/docker-stack/index.html) using instructions from [Airflow's Documentation](https://airflow.apache.org/docs/docker-stack/index.html).
2. Extend the prebuilt image by using a Dockerfile to install the `otel` extra. You can replace the latest tag with your desired version of the Airflow image.

```
FROM apache/airflow:latest
RUN pip install --no-cache-dir "apache-airflow[otel]==${AIRFLOW_VERSION}"
```

## Configuration [#configuration]

You need to configure the Airflow OpenTelemetry metrics to send data to an [OpenTelemetry Collector](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/collector/opentelemetry-collector-intro/) that reports data to a New Relic [OTLP Endpoint](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/opentelemetry-setup/#note-endpoints) using a <InlinePopover type="licenseKey" />.

<Callout variant="important">
  Airflow does not currently supporting sending OpenTelemetry data with authentication headers, making the OpenTelemetry Collector a requirement to authenticate with New Relic.
</Callout>

### OpenTelemetry Collector Configuration [#configuration-collector]

1. Follow the [basic collector example](/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/collector/opentelemetry-collector-basic/) to setup your OpenTelemetry Collector.
2. Configure it with your appropriate OTLP Endpoint. For example, `https://otlp.nr-data.net:4317`.
3. For authentication, add your <InlinePopover type="licenseKey" /> to the environment variable `NEW_RELIC_LICENSE_KEY` so that it populates the `api-key` header.
4. Ensure port 4318 on the collector is open and available to the running Airflow instance. (For docker, you may need to use a [docker network](https://docs.docker.com/network/).)
5. Launch your collector.

### Airflow Metrics Configuration [#configuration-airflow]

Airflow sends metrics using OTLP over HTTP. To send this data to our OpenTelemetry Collector it will need to be sent to port 4318. Airflow has multiple methods of [setting configuration options](https://airflow.apache.org/docs/apache-airflow/stable/howto/set-config.html).

<Callout variant="important">
  If your environment has Airflow running in a docker container alongside the OpenTelemetry Collector, you will need to change the `otel_host` setting from `localhost` to the container address of the collector.
</Callout>

Choose one of the following methods to set the required options for Airflow.

1. Set the required options in the `airflow.cfg` file.

```
[metrics]
otel_on = True
otel_host = localhost
otel_port = 4318
otel_ssl_active = False
```

2. Or, set the required options as environment variables.

```
export AIRFLOW__METRICS__OTEL_ON=True
export AIRFLOW__METRICS__OTEL_HOST=localhost
export AIRFLOW__METRICS__OTEL_PORT=4318
export AIRFLOW__METRICS__OTEL_SSL_ACTIVE=False
```

<Callout variant="tip">
  Airflow has [additional settings](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/metrics.html#setup-opentelemetry) for metrics that may be useful. This includes the ability to [rename metrics](https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/metrics.html#rename-metrics) before sending, which is helpful if metric names exceed the 63 byte limit for OpenTelemetry.
</Callout>

## Validation [#validation]

Run a DAG or pipeline to see Airflow data in New Relic.

1. Log into Airflow.
2. Click the run button on one of the existing tutorial DAGs, or your own.
3. Wait for the pipeline to finish running.
4. Go to **[one.newrelic.com > All capabilities](https://one.newrelic.com/all-capabilities) > APM & services > Services - OpenTelemetry > Airflow**.
5. Click **Metrics Explorer** to visualize metrics for pipeline executions.

## Building dashboards [#building-dashboards]

With Airflow metrics, you can build dashboards around individual pipelines, overall performance, or view a comparison between different pipelines. Click here to learn more about [querying your metrics](/docs/data-apis/understand-data/metric-data/query-metric-data-type/).

Use the following query to retrieve a list of all reported metrics for Airflow. Be sure to change the limit if your metric names exceed it.

```
SELECT uniques(metricName) FROM Metric WHERE entity.name = 'Airflow' AND metricName LIKE 'airflow.%' SINCE 30 MINUTES AGO LIMIT 100
```

This query shows a comparison of different completion times for successful runs of different DAGs.

```
SELECT latest(airflow.dagrun.duration.success) FROM Metric FACET dag_id WHERE entity.name = 'Airflow' SINCE 30 minutes AGO TIMESERIES
```

<img
  title="Screenshot showing sample Airflow DAG runs in New Relic"
  alt="Screenshot showing sample Airflow DAG runs in New Relic"
  src={opentelemetryAirflow01}
/>

This query shows counts of failed DAG runs, which can be used to build alerts for critical pipelines.

```
SELECT count(airflow.dagrun.duration.failed) FROM Metric FACET dag_id WHERE entity.name = 'Airflow' SINCE 30 minutes AGO TIMESERIES
```

<img
  title="Screenshot showing sample Airflow failures in New Relic"
  alt="Screenshot showing sample Airflow failures in New Relic"
  src={opentelemetryAirflow02}
/>

<Callout variant="important">
  Airflow's OpenTelemetry metrics are not maintained by New Relic, so if you have any issues with the instrumentation, [create a new issue in Airflow's GitHub repo](https://github.com/apache/airflow/issues).
</Callout>

<InstallFeedback />
