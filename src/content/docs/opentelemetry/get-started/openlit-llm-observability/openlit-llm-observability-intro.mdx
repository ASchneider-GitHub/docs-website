---
title: 'LLM observability with OpenLIT'
tags:
  - Integrations
  - LLM observability with OpenTelemetry
  - GenAI Observability with OpenTelemetry
  - OpenTelemetry
  - OpenLIT
metaDescription: Set up OpenTelemetry-based LLM observability with New Relic and OpenLIT.
freshnessValidatedDate: 2024-08-12
---

While OpenTelemetry offers a powerful standard for collecting general application data (traces, metrics, logs), it lacks the ability to capture key performance indicators (KPIs) specific to AI models. This includes crucial metrics like model name, version, prompt and completion tokens, and temperature parameters. These details are essential for effectively monitoring and troubleshooting AI model performance.

OpenLIT emerges as a solution, specifically designed to address this gap in AI model observability. Built on top of the OpenTelemetry framework, OpenLIT provides seamless integration and extends its capabilities. It offers support for popular AI frameworks like OpenAI, HuggingFace, Pinecone, and LangChain.

<DNT>**Key Benefits of OpenLIT:**</DNT>
* <DNT>**Standardized Collection of AI Model KPIs:**</DNT> OpenLIT ensures consistent capture of essential model performance metrics, enabling comprehensive observability across diverse frameworks.
* <DNT>**Deeper Insights into LLM Applications:**</DNT> With its open-source SDK, OpenLIT empowers you to gain thorough understanding of your Large Language Model (LLM) applications.
This page describes common set up steps for OpenTelemetry based APM monitoring with New Relic.

OpenLIT empowers developers to leverage the strengths of OpenTelemetry while gaining the additional functionalities required for effective AI model monitoring and performance optimization.

## Before you start [#prereqs]

* [Sign up](https://newrelic.com/signup) for a New Relic account.
* Get the [license key](https://one.newrelic.com/launcher/api-keys-ui.launcher) for the New Relic account to which you want to report data.

<Steps>
  <Step>
## Instrument your LLM Model with OpenLIT [#instrument]

Since New Relic natively supports OpenTelemetry, you just need to route the traces and metrics to New Relic’s endpoint and set the API key:

```env
OTEL_EXPORTER_OTLP_ENDPOINT = https://otlp.nr-data.net:443
OTEL_EXPORTER_OTLP_HEADERS = "api-key=YOUR_NEWRELIC_LICENSE_KEY"
```

* The OpenTelemetry Protocol (OTLP) exporter sends data to the [New Relic OTLP endpoint](/docs/opentelemetry/best-practices/opentelemetry-otlp).

<DNT>**Example: OpenAI LLM Model with LangChain**</DNT>
  ```python
  import OpenLIT
  import os
  import time
  from langchain_openai import ChatOpenAI

  os.environ['OPENAI_API_KEY'] = 'OPENAI_API_KEY'
  os.environ['OTEL_EXPORTER_OTLP_ENDPOINT'] = 'https://otlp.nr-data.net:443'
  os.environ['OTEL_EXPORTER_OTLP_HEADERS'] = 'api-key=YOUR_NEWRELIC_LICENSE_KEY'

  openlit.init()

  def add_prompt_context():
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0)
    chain = llm
    return chain

  def prep_prompt_chain():
    return add_prompt_context()

  def prompt_question():
    chain = prep_prompt_chain()
    return chain.invoke("explain the business of company Newrelic and it's advantages in a max of 50 words")

  if  __name__ == "__main__":
    print(prompt_question())
  ```
  </Step>

  <Step>
## View your data in the New Relic UI [#view-data]

Once your app is instrumented and configured to export data to New Relic, you should be able to find your data in the New Relic UI, you can Import the LLM Observability pre-built Dashboard by following the below steps:

1. Go to one.newrelic.com > Dashboards.
2. In the top-right corner, click Import dashboard.
3. Copy the dashboard JSON provided [here](https://docs.openlit.io/latest/connections/new-relic#dashboard).
4. Paste the dashboard JSON text directly into the text area.
5. Choose the account and permission settings for the dashboard. You can’t change the account once you’ve set it, but you can change the permissions at any time.
6. Click Import Dashboard.

If you can't find your entity and don't see your data with NRQL, see [OTLP troubleshooting](/docs/opentelemetry/best-practices/opentelemetry-otlp-troubleshooting).
<InstallFeedback />
  </Step>
</Steps>
