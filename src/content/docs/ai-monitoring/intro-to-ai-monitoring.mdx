---
title: 'Introduction to AI monitoring'
metaDescription: 'AI monitoring lets you observe the AI-layer of your tech stack, giving you a holistic overview of the health and performance of your AI-powered app.'
freshnessValidatedDate: 2024-11-04
---

AI monitoring is our AI observability solution that gives you end-to-end visibility into your LLM-powered apps. Enabled through our APM agents, you can monitor AI apps for app and model performance, costs, and response quality. Explore how users interact with your AI assistant, dig into trace-level details about an AI event, or compare the performance of different models across app environments. 

<img
  title="Trace waterfall for AI monitoring"
  alt="A screenshot that shows the trace waterfall page for an individual AI response"
  src="/images/ai_screenshot-full_ai-responses-intro-page.webp"
/>

<figcaption>
  Go to **[one.newrelic.com](https://one.newrelic.com) > AI monitoring > AI responses**.
</figcaption>

## How does AI monitoring work? [#how-it-works]

To get started with AI monitoring, you'll instrument your AI-powered app with one of our APM agents. Once you've instrumented your app, you can enable AI monitoring on the configuration level so the agent can detect AI data.

When your AI assistant receives a prompt and returns a response, the agent captures metric and event data generated from external LLMs and vector stores. It parses information about completion, prompt, and response tokens, how many requests pass through your OpenAI, Bedrock, or NVIDIA NIM models, and whether your end users found your model's responses helpful. 

You can access all of this information from the New Relic platform, make comparisons across apps and models, and create dashboards to help you manage your AI data effectively.

## Improve AI performance with AI monitoring [#improve-performance]

<img
  title="AI responses page"
  alt="A screenshot of the AI responses page"
  src="/images/ai_screenshot-full_AI-responses-overview.webp"
/>

<figcaption>
  To overview your AI-powered app's performance: Go to **[one.newrelic.com](https://one.newrelic.com) > AI monitoring > AI responses**.
</figcaption>

AI monitoring can help you answer critical questions about AI app performance: are your end users waiting too long for a response? Is there a recent spike in token usage? Are there patterns of negative user feedback around certain topics? With AI monitoring, you can see data specific to the AI-layer:

* [Identify errors in specific prompt and response interactions](/docs/ai-monitoring/explore-ai-data/view-ai-responses) from the response table. If you're looking to make improvements to your AI models, [learn how to analyze your model data in New Relic](/docs/ai-monitoring/explore-ai-data/view-model-data).
* If you're using different models across app environments, you can [compare the cost and performance of your apps before deploying](/docs/ai-monitoring/view-ai-data/#model-comparison).
* Are you concerned about data compliance? [Learn how to create drop filters](/docs/ai-monitoring/drop-sensitive-data) to drop sensitive data before you send it to New Relic.

## Get started with AI monitoring [#get-started]

Ready to get started? Make sure to [confirm that you can instrument your AI library or framework](/docs/ai-monitoring/compatibility-requirements-ai-monitoring). You may need to update the agent if you've already instrumented your app.

When you're ready, use our doc to [manually install AI monitoring](/install/ai-monitoring). This doc directs you to the relevant procedures for installing an APM agent, then walks you through configuring the agent for AI monitoring.
