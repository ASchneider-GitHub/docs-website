---
title: 'Introduction to AI monitoring'
metaDescription: 'AI monitoring lets you observe the AI-layer of your tech stack, giving you a holistic overview of the health and performance of your AI-powered app.'
freshnessValidatedDate: never
---

import aiTraceViewIntroPage from 'images/ai_screenshot-full_trace-view-intro-page.webp'

import aiAIResponsesOverview from 'images/ai_screenshot-full_AI-responses-overview.webp'

When people talk about artificial intelligence, they can mean different things. At New Relic, when we say AI, we mean the layer of your environment that uses a large language model (LLM) to generate a response when it receives an end user prompt. 

With AI monitoring, you can measure the performance of the engine powering your AI assistant, so that you can ensure your users have the best possible experience. To get started, all you need is to install one of our APM agents and enable AI monitoring.

<img
    title="Trace waterfall for AI monitoring"
    alt="A screenshot that shows the trace waterfall page for an individual AI response"
    src={aiTraceViewIntroPage}
/>

<figcaption>
    Go to **[one.newrelic.com](https://one.newrelic.com) > AI monitoring > AI responses**, then select a response row. 
</figcaption>

## How does AI monitoring work? [#ai-monitoring-works]

To get started with AI monitoring, you'll install one of our APM agents to instrument your app. Instrumentation means that your app can be measured, which lets the agent capture data about app behaviors. Once instrumented, you need to enable AI monitoring on the configuration level. 

Enabling AI monitoring allows the agent to recognize AI metadata associated with AI events. When your AI receives a prompt and returns a response, the agent can recognize data generated from external LLMs and vector stores, or parse out information about tokens usage. 

## Improve AI performance with AI monitoring [#improve-performance]

<img
    title="AI responses page"
    alt="A screenshot of the AI responses page"
    src={aiAIResponsesOverview}
/>

<figcaption>
    To overview your AI-powered app's performance: Go to **[one.newrelic.com](https://one.newrelic.com) > AI monitoring > AI responses**.
</figcaption>

AI monitoring can help you answer critical questions about AI app performance: are your end users waiting too long for a response? Is there a recent spike in token usage? Are there patterns of negative user feedback around certain topics? With AI monitoring, you can see data specific to the AI-layer:

* Refer to the responses table to identify errors in specific prompt and response interactions. If an error occurs, open the trace waterfall view to scope to the methods and calls your AI-powered app makes when generating a response. 
* Did your prompt engineers update the prompt parameters for your AI? You can track whether token usage spiked and dropped after this change, helping you make decisions that keep costs down.  
* Maybe you're adjusting the logic behind an app in development, but you want to ensure that it's cost efficient before it goes into production. If you're using different models in different app environments, you can compare the cost and performance of apps against each other.

## Get started with AI monitoring [#get-started-ai-monitoring]

Ready to get started? Make sure to [confirm that your AI monitoring can instrument your AI library or framework](/docs/ai-monitoring/compatibility-requirements-ai-monitoring). You may need to update the agent if you've already instrumented your app. 

When you're ready, use our doc to [manually install AI monitoring](/docs/install/ai-monitoring). This doc will direct you to the relevant docs for installing an APM agent, then walks you through configuring the agent for AI monitoring. 