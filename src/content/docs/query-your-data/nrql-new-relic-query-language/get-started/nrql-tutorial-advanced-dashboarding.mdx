---
title: "Advance your dashboarding with NRQL"
tags:
  - NRQL tutorial
  - 'NRQL: New Relic query language'
  - Get started
  - Tutorial
metaDescription: "Learn how to use NRQL to improve your dashboarding"
---

import queriesnrql2tutorial1 from 'images/queries-nrql_screenshot-crop-tutorial2-1.webp'

Welcome! We hope seeing example queries and explanations in the context of your own data helps you better understand how to transform data into powerful visuals. (Try queries from this course on different event types in your own account(s) to really understand their power!)

We are now moving on to even more advanced concepts. You may not use these functions and features on every single dashboard, but they will certainly come in handy when tackling specific problems and requirements.

In this level, we will cover faceting by case, advanced aggregation functions, the value of the EXTRAPOLATE keyword, filtering aggregation functions, and how to override values. Remember if you've chosen an account without APM data. You will see backup queries that may not match the lesson description. 

Specifically, you'll learn how to use:

* Advanced aggregation functions like `filter()`, `apdex()`, `rate()funnel()`, `histogram()`.
* The `EXTRAPOLATE` clauses.
* `FACET CASES()`, including how to use attribute and group matching values.
* `filter()` to combine Event Types.
* Overriding values, when necessary.

### Use advanced aggregators 
<Steps>
    <Step>
*Calculating Rate*
Let's start with the rate() function. It allows you to visualize the frequency of events over time. This is helpful when you want to understand the frequency of events in small periods of time within larger time windows.

In the example below, we display the average frequency of requests per 5 minutes for the last hour. We compare this to the previous hour’s 5-minute average frequency. Notice the query uses SINCE 1 hour ago, this is the overall time window in which we are calculating the rate.

You can use rate() to calculate requests per minute or requests per second by setting the time interval to either 1 minute or 1 second.

<CollapserGroup>
    <Collapser
        id="code_copy_1"
        title="Copy this code"
    >
```sql
SELECT rate(count(*), 5 minutes) 
FROM Transaction 
SINCE 1 hour ago 
COMPARE WITH 1 hour ago
```
    </Collapser>
</CollapserGroup>

<img
    title="Calculate range"
    alt="A screenshot of a query using Since and Compare to capture data within a time range"
    src={queriesnrql2tutorial1}
/>
    </Step>
    <Step>
#### Funnel Charts
Many New Relic customers use funnel charts to understand end-user behavior. Funnel charts track the occurrence of an attribute value across multiple records. They are commonly used to visualize how successfully users' progress through defined paths, and are especially powerful when using custom attributes.

Here we use the funnel() aggregator function to visualize how many users visit the home page, then proceed to another page. The first parameter is the identifying attribute for the unique entries we're counting. In this case, New Relic Browser assigns and retains a session ID attribute for each user on your site (subject to cookies being enabled). You can also set your own session ID using custom attributes.

The remaining parameters determine how each step of the funnel is calculated. They are written in the format ", WHERE attr OP value". In this case, we provide two: we want to know how many user sessions visited the homepage, then also how many of these also navigated to other pages. Try this query on your own data to get a reasonable result.

```sql
SELECT funnel(session, WHERE pageUrl LIKE 'http%//%.%.com/' AS 'Home', WHERE pageUrl NOT LIKE 'http%//%.%.com/' AS 'Any Other Page') 
FROM PageView 
SINCE 1 week ago 
UNTIL now
```
<img
    title="Calculate range"
    alt="A screenshot of a query using Since and Compare to capture data within a time range"
    src={queriesnrql2tutorial1}
/>
    </Step>
    <Step>
Aggregator Filters
filter() is a powerful tool that allows you to aggregate multiple data points in a single query, offering more control over which events are included in function results. In this example, we use filter() to return the separate values for total transactions, total web transactions, and total non-web transactions:

<Tabs stacked>
	<TabsBar>
        <TabsBarItem id="1">
            Example
        </TabsBarItem>
        <TabsBarItem id="2">
            Copy this query
        </TabsBarItem>
    </TabsBar>

    <TabsPages>
        <TabsPageItem id="1">
<img
    title="Calculate range"
    alt="A screenshot of a query using Since and Compare to capture data within a time range"
    src={queriesnrql2tutorial1}
/>
        </TabsPageItem>
        <TabsPageItem id="2">
```sql
SELECT count(*) as 'All Transactions', filter(count(*), WHERE transactionType = 'Web') as 'Web Transactions', filter(count(*), WHERE transactionType !='Web') as 'Non-Web Transactions' 
FROM Transaction 
SINCE 24 hours ago
```
        </TabsPageItem>
    </TabsPages>
</Tabs>

Since it returns a number, you can also perform math on its results. For example, we can divide total web transactions by all transactions to determine what percent of transaction were web transactions:

QUERY
IMAGE
    </Step>
    <Step>
Histograms
Histograms allow you to better visualize the distribution of your data. This assists in understanding how data points are grouped by frequency, not just averages. The histogram() function takes three arguments:
the attribute you want to plot (such as duration)
the maximum value of the range you want to consider (such as "1" for 1 second or less)
the number of buckets you want data grouped in
In our example, we create a histogram() chart for all duration values between 0 and 1 second, grouped into 50ms buckets. We do this by specifying "20" for the number of buckets. All the durations larger than 1 second are grouped together in the last bucket.

QUERY
IMAGE
    </Step>
    <Step>
Apdex
The apdex() function calculates an Apdex score on any numerical value (such as duration). You can calculate Apdex for one or more specific transactions, account for custom attribute values, and even provide your own Apdex-T value without interfering with application settings. In this example, we have provided the function with an attribute of "duration" and an Apdex-T value of 0.08:

QUERY
IMAGE
    </Step>
    <Step>
We can also add the TIMESERIES operator to chart the data over time. Notice this also plots the Apdex satisifed, tolerated, and frustrated thresholds.

QUERY
IMAGE
    </Step>
</Steps>

We just explored a whole new set of visualizations with funnel() and histogram(). We also learned how filter() can help us get more specific in queries with WHERE clauses, and how rate() can display the rate of an attribute over time.

These queries further advance your NRQL ability. Apdex is an industry standard and is applicable in many scenarios. Funnels can track progress through desired paths. Histograms visualize the clear distribution of the data; and filters let you get super specific with your returned values. Next, we will learn about EXTRAPOLATE.

### Use extrapolate

The New Relic Database (NRDB) receives and processes enormous amounts of data, every day, at lightning speed! When APM records a large amount of event data, New Relic agents implement a sampling technique to continue collecting meaningful data while reducing potential impact to your applications. This usually only happens when a single event in an application or service handles extremely high volumes of requests. If multiple agents are spread across multiple load-balanced instances of a service, this limit might never be observed.

Let's discuss what we can do when this happens. The EXTRAPOLATE operator tells New Relic to mathematically compensate for the effects of sampling, thereby returning results that more closely represent activity in your system. We store an extra value to record how many similar events occured over the limit. This allows New Relic to deliver statistically accurate results. There is no fallback query for this if you have no APM data due to the fact this is specific to Transaction events.

QUERY
IMAGE

You might be thinking "are we hitting the limit?" Well, try removing EXTRAPOLATE from the query, and see if your count changes. If it doesn't, you most likely haven't reached the limit.

When EXTRAPOLATE is included in a query, the ratio between the reported events and the total events is calculated. This ratio is then used to extrapolate an approximation of unsampled data. Keep in mind that only some queries support its use. When included in a NRQL query that doesn’t support it, or that doesn't use sampled data, it will have no effect.

Note that EXTRAPOLATE is most useful for homogenous data (like throughput or error rate). It's not effective when attempting to extrapolate a count of distinct things (like uniqueCount() or uniques()). This clause works only with NRQL queries that use one of the following aggregator functions:

* apdex
* average
* count
* histogram
* sum
* percentage
* rate
* stddev

### Use facet cases

<Steps>
    <Step>
As you learned in previous lessons, FACET is a great way to both segment your data, and understand it from differently grouped perspectives (such as seeing average response time based on different response codes). When you use FACET, NRDB organizes data into groups based on the values of provided attributes. But what if you wanted to group multiple values together, such as HTTP response codes 200, 201, etc.?

FACET CASES() solves for this issue by allowing you to choose how facet buckets are broken out. The operator takes any number of parameters in the format "WHERE attr OP value". In the example below we've categorized all transactions with response code starting with "2" into a "2xx Responses" bucket. We could also do this for 3xx, 4xx, and 5xx response codes to group our data in ways that increase readability and help us understand what's happening in our application(s).

QUERY
IMAGE
    </Step>
    <Step>
As you can see, these groupings are useful but difficult to read. Let's clean them up using something we learned in level 2 of this course:

QUERY
IMAGE
    </Step>
</Steps>

FACET CASES() allows us to match and group attributes with mulitple, interesting values we want combined. There are many useful scenarios for this functionality. It's also even more powerful when custom data is tagged onto your transaction data, allowing you more granularity and control in navigating and grouping data.

### Filter by event type

<Steps>
    <Step>
We're truly becoming NRQL wizards! Next we'll explore something few New Relic customers are even aware of: filtering to event types.

So far, we've made queries that pull data from a single source. But what if you want to plot 2 data points that are stored as two different event types? Querying NRDB data is not limited to a single event type! To query from multiple event types you can include each event type seperated by a comma.

QUERY
IMAGE
    </Step>
    <Step>
To make this even more useful, the eventType() function tells us which event type a record is from. We can use this to control our data output. In this example, we see the total number of Transaction and PageView events combined, as well as the totals for only Transaction and PageView.

QUERY
IMAGE
    </Step>
    <Step>
Let's look at this in more detail: count(*) is the total number of both Transaction and PageView events. However, we can use the aggregator function filter() we recently learned about to do something unique. We tell it WHERE eventType()='PageView'. This invokes the filter function to observe the event type as part of the total result set, then filter to display only those specific events. We can even add TIMESERIES to visualize 2 directly comparable data points on a line graph.

QUERY
IMAGE
    </Step>
</Steps>

We have managed to locate, return, and graph data from two different event types. This is an example of how NRQL can allow you to navigate any necessary data quickly and succinctly; no complex joining or join statements required!

### Override values

<Steps>
    <Step>
Counting NULL Values
Sometimes data simply doesn't report in the format you need. For instance, sometimes integers are returned as strings, but you need them as integers to perform maths. Or maybe you get a NULL result, but in your case NULL actually means 0. Don't worry! We hear you, and we've added functionality to address this.

NULL values on attributes can appear on both out-of-the-box and custom data. When you use aggregators such as count() and average(), NRQL automatically removes NULL values from the calculation, only performing the function on events without NULL values. NRQL lets you account for unexpected NULL values in calculations by using the "OR value" clause. For example, if you wanted to make sure NULL values for your "cartValue" attribute are counted as 0, you could use "cartValue OR 0" in your query.

In this example, running count() on ApdexPerfZone only counts the number of times ApdexPerfZone has a value. But if we add "OR 'Null'" to the argument, we can count all transactions where ApdexPerfZone exists, and also those where the value is null.

QUERY
IMAGE
    </Step>
    <Step>
Coercion
NRQL does not automatically apply coercion. This means a float stored as a string is treated as a string, and cannot be used by mathematical functions like sum() or average(). To override this behavior, use boolean() or numeric() to convert arguments to a boolean or numerical values. In this example, an average() function on "httpResponseCode" provides no value since this attribute is a string. But if we convert the attribute to a number using numeric(httpResponseCode), we can use the average() function successfully.

QUERY
IMAGE
    </Step>
    <Step>
Another common example is BOOLEAN (TRUE or FALSE) values. These are often incorrectly formatted as strings. When this happens, don't worry! You can change how the source sends the data to make it a proper boolean. Or, you can use the boolean() function. The example query below returns the same result, but that is because we're using a value sent by the agent as a BOOLEAN. If your attribute was a string "TRUE", boolean() would convert it into a proper boolean format, allowing the query to run as intended.

QUERY
IMAGE
    </Step>
    <Step>
You can also convert boolean and numeric values to strings by using the string() function. Where numeric values are floating-point numbers you can use the optional precision argument to limit the number of decimal places for the string. This query returns the duration value as a string limited to three decimal places.

QUERY
IMAGE
    </Step>
</Steps>

Sometimes the devil is in the details. Here we've given you the power to control your data formats, and tell NRQL how you want it to act. NRQL operates in the manner we deem most logical, but if that does not suit your unique scenario, you can use the functions explored in this lesson to override values.

### Use string concatenation

<Steps>
    <Step>
There may be some cases where you need to append and/or prepend text to the returned value of an attribute. This can be achieved using the concat() function.

You can provide upto 20 arguments for the concat() function to concatenate into a string.

QUERY
IMAGE
    </Step>
    <Step>
We can limit the number of decimal places that are used for any floating point numbers in the values of the concatenated attributes. To do this we use the optional precision: argument as the last value. In this example we are appending 's' to denote seconds, and limiting the value to 3 decimal places.

QUERY
IMAGE        
    </Step>
    <Step>
Values that start with 'http(s)' are automatically displayed as links which can be clicked to open a new page, which means it is possible to create integrations to solutions where a dynamic URL can be used to open a related page to the entity. The following example demonstrates an example URL where the query parameter values are set by the attribute values.

QUERY
IMAGE
    </Step>
</Steps>

You can use the concat() function to combine values together (e.g. city and country for location), and prepend/append additional strings to present the data as you need.

<CollapserGroup>
    <Collapser
        id="summary"
        title="Lesson summary"
    >
In this section we explored specific, powerful NRQL functionality. These skills will undoubtedly serve you next time you're in the trenches, diving into the nitty-gritty of your data.

You're now a Level 3 NRQL expert! Believe it or not, there are even more features and functions we want to showcase in the next section.
    </Collapser>
</CollapserGroup>

### What's next?

Content forthcoming