---
title: "Control your data with NRQL"
tags:
  - NRQL tutorial
  - 'NRQL: New Relic query language'
  - Get started
  - Tutorial
metaDescription: "Learn how to use NRQL to control your data."
---

Welcome to Level 2. In the previous level, we explored the fundamentals of building queries and manipulating results to retrieve the data we want. We covered basic query structure, defining time windows, and how to select specific attributes to observe. We also began learning how to aggregate and display data on line graphs and other visualizations.

In this section, we will delve deeper and explore even more functions for creating interesting aggregations. We will learn how to compare returned data with previous time periods, group data into more specific time windows, be more granular with `SINCE` and `UNTIL` functionality, and explore using wildcards in filters. We will even discuss how to rename attributes to be more user-friendly.

We had a gentle introduction to aggregation in Level 1 by using count(), average(), sum(), max() and min() to transform data in meaningful ways. Next we will explore even more powerful functionality. In this lesson we will learn how to find and count unique values, locate the most recent or oldest entries for an attribute, and work with percentages and percentiles.

You'll learn how to:

* Query for unique values using uniques(attributeName)
* Determine how many unique values exist in an attribute using uniqueCount(attributeName)
* Retrieve the earliest(attributeName) and latest(attributeName) within a specific time window
* Calculate percentages based on a qualifer or other data point with percentile()
* Perform basic math using attributes and aggregation functions, or a combination of both
* Cast attribute names to something custom and more readable
* Search to include/exclude using wildcards with LIKE/NOT LIKE, or limit results to those IN a list or NOT IN that list
* Query within more advanced time windows using dates, epoch, and WITH TIMEZONE
* Group data into interesting time windows using time-based cohorting

Again if you have chosen an account without Transaction event reporting, we will fallback to other queries that are similar. Let's get started!

### Aggregate functions
<Steps>
    <Step>
In a previous lesson we learned how the count() function can return a simple count of available records. To determine the number of unique values recorded for an attribute over a specified time range, we can use the uniqueCount() function. In this function, we provide the attribute we want to inspect as an argument. For instance, here we display all the unique hosts:

IMAGE 

QUERY
    </Step>
    <Step>
To optimize query performance, the function above returns approximate results for queries that inspect more than 256 unique values. To return the actual list of unique values for an attribute over a specified time range, we can use the uniques() function. 

IMAGE 

QUERY

A second limit parameter may be provided: uniques(attribute[,limit]). When it is not provided, the default limit of 1,000 unique attribute values per facet is applied. You may specify a different limit value, up to a maximum of 10,000.
    </Step>
    <Step>
To retrieve the most recent value of an attribute over a specified time range, use the latest() function. In this sample query, we are locating the most recent response time for a web transaction in the last day. This could help us locate the latest value for an intermittently reporting transaction or service.

IMAGE

QUERY
    </Step>
    <Step>
Using the earliest() function will do the opposite; that is, it will return the earliest value of an attribute recorded in the specified time range. In this sample query, we retrieve the earliest response time for a web transaction in the last day. If data is consistently reporting, this will simply be the data point from the earliest event 24 hours ago.

QUERY

IMAGE
    </Step>
    <Step>
There may also be scenarios in which you need percentages instead of counts, sums, or averages. Using the percentage() function allows you to calculate the percentage of a value in the data set that matches a specified condition. This function takes two arguments: the first is an aggregator function for your desired attribute, such as count(). The second is a WHERE condition to specify the subset of data you'd like to query.

In this sample query, we are finding the percentage of transactions over the last day that had a duration (or response time) greater than 100 milliseconds.

QUERY
IMAGE
    </Step>
    <Step>
It's very common to view application performance and/or customer experience data using percentiles rather than averages. With the percentile() function we can understand the experience of the nth percentile.

For example, let's say we want to know what the worst experience (highest duration) of 98% of our customers is today. We can ask NRDB for percentile(duration, 98) from the last 24 hours.        
    </Step>
</Steps>

As you can see, aggregation can manipulate data in powerful ways. We used uniqueCount() to count the unique entries of a particular attribute. But you could also use this to identify a count of unique machines, reporting containers, or even how many custom data points are sent to New Relic. And, if we want to know what unique values are available to query, we can always ask for a list using uniques().

The latest()/earliest() functions are particularly useful when dealing with sparse data, or investigating when something began or stopped reporting (assuming the data is still stored in New Relic).

We also learned that percentage() can determine what percentage of events matched a qualifier compared with the overall result set.

Finally, we saw how to observe percentiles. For example, you can use percentile() as a Key Performance Indictator by setting a goal to ensure 90% of all end user transactions are faster than a provided duration.

We are getting much more advanced at dancing with our data! In the next lesson we will learn how to do basic mathematics with NRQL.

### Use math operators

<Steps>
    <Step>
NRQL supports basic math operators. You can perform addition (+), subtraction (-), multiplication (*), and division (/) on both numeric attribute values, and results of aggregator functions.

For example, when a transaction event is recorded we capture both the total response time (as duration) and database response time (as databaseDuration). But what if we want to compute the average time spent outside of database processing? Well, let's start by calcuating that value for each event in our data set.

QUERY
IMAGE

    </Step>
    <Step>
Great! We just performed some basic math. This is useful if we are listing individual events. But what if we want to know the average duration of transactions without the database time? Conveniently, we can do the arithmetic within the function:

QUERY
IMAGE        
    </Step>
    <Step>
Now, what if we wanted to get even more complicated and subtract, divide, and multiply in the same query to figure out the duration without database time, as a percentage of overall time? Well, we can add the math:

QUERY 
IMAGE
    </Step>
</Steps>

New Relic reports timings as part of your events, so you can use them to calculate interesting data points, or even generate percentage results.

You can further maximize the power of basic mathematics by doing things like timing custom actions or events, or sending custom data. For instance, an e-commerce platform that reports data about order sizes, which transactions were successful orders, and payment methods could calculate values such as the conversion rate of orders vs. unique customer visits.

### Label attributes

<Steps>
    <Step>
As you start performing more complex NRQL functions, you will notice that the name displayed for queried attributes might not be helpful - especially for others that don't know NRQL! Let's consider an example using what we learned in basic math.

QUERY
IMAGE

    </Step>
    <Step>
We can use the AS clause after a function or attribute to give the result a more readable, meaningful name. This makes it easier for you and your team(s) to understand exactly what a chart represents.

QUERY
IMAGE
    </Step>
This may seem purely aesthetic, but when you're building detailed dashboards, it's important to clearly label your data. This ensures zero ambiguity for anyone viewing your widgets, billboards, line charts or tables.

We'll refer back to this in upcoming examples about grouping, to explore how AS can create clean result sets in more advanced scenarios too.
</Steps>

### Compare time windows

<Steps>
    <Step>
We have learned how to use time ranges with SINCE and UNTIL clauses. But what if we want to compare values fromdifferent time ranges? We can achieve this with the COMPARE WITH clause.

We use SINCE and UNTIL to define our period of interest. Then, we denote the time period we'd like to compare against with a COMPARE WITH [time period] AGO clause containing a relative offset value.

Specifically, in the sample query below we compare the last day against the previous week using a relative offset of 1 week ago.   

QUERY
IMAGE
    </Step>
    <Step>
To map the comparison of values over time, add TIMESERIES. This creates a line chart of the comparison, allowing you to visualize how this period compares to recent data, and track it over time.

QUERY
IMAGE
    </Step>
    <Step>
You can also specify many different relative time periods in the same format, similar to UNTIL. For instance, you may specify 4 WEEKS AGO or 6 HOURS AGO.

QUERY
IMAGE
    </Step>
Comparisons can quickly answer questions about what's happening in your applications. Are different sales, performance, MTTR, or error values up or down compared to last week? And, if you are investigating an issue, comparing aperiod of problemantic performance to a period of normal performance can be very useful.
</Steps>

### Use wildcard filters

<Steps>
    <Step>
We now know how to use a WHERE clause to filter the results in our query. Aside from using standard comparison operators, we can also use LIKE and NOT LIKE if we want to determine whether an attribute contains or does not contain a specified substring. In order to achieve this, we need to use the percent (%) symbol as a wildcard anywhere in the string.

In our sample query, we are getting the number of transactions with the term "Web" anywhere (beginning, middle or end) in the name.

QUERY
IMAGE
    </Step>
    <Step>
If we change our query to use NOT LIKE instead, then we will get the number of transactions that do not contain the word "Web" in its name.

QUERY
IMAGE        
    </Step>
    <Step>
We used the wild card % at the beginning and end, which means that we are checking the value of the attribute we chose if it contains "Web" anywhere in the text. Equally, you could use `%Web` OR `Web%` to match something that ends in "Web" or starts with "Web", respectively.

You can also add the wildcard in between strings for a more refined search. This query will check for a transaction name that contains the word "Web" followed by any text, but then also contains the word "index" followed by any number of characters. So, the results will only be transactions with "Web" and "index" in the name.        

QUERY
IMAGE
    </Step>
    <Step>
What if you need to be extremely specific and the names don't have a common string you can match using wildcards. The IN and NOT IN operators allow us to specify a set of values that we would like to check against an attribute. Instead of specifying multiple WHERE clauses with AND or OR operators, we can simplify our condition by listing the values in parentheses separated by commas.

In this sample query, we are counting the number of transactions whose subtype is either "SpringController" or "StrutsAction". If you change our query to use NOT IN instead, then we will get the number of transactions whose subtype is neither "SpringController" nor "StrutsAction".

QUERY
IMAGE
    </Step>
</Steps>

You can now control your data and manipulate it to do what you need, allowing you to construct powerful, meaningful dashboards and alerts.

### Specify time ranges

<Steps>
    <Step>
The SINCE and UNTIL clauses are not limited to relative time ranges. You can also provide a specific date and/or time. In the following sample query, we include a SINCE date in YYYY-MM-DD format. This is useful when creating SLA reports for a specified period of time.

QUERY
IMAGE
    </Step>
    <Step>
You can even include specific time with the format YYYY-MM-DD HH:MM. In this query, you can see the data is set at 6pm.

QUERY
IMAGE        
    </Step>
    <Step>
Sometimes, as an engineer, you might receive an event time in epoch (unix) time. Conveniently, epoch timestamps are an acceptable value in SINCE and UNTIL clauses, so you don't have to translate these values into another date format.

QUERY
IMAGE
    </Step>
    <Step>
When NRDB shows data over a period of time, it assumes you want to see the data from the perspective of your timezone. But with dispersed international teams, your "today" could be someone else's "tomorrow" or "yesterday" depending on their location.

You can use the WITH TIMEZONE clause to define a timezone to display data from. This affects the interpretation of values in SINCE and UNTIL clauses.

Consider the two example charts below. Each query has a specified timezone using WITH TIMEZONE. The two are 8 hours apart. Notice the pattern of data is the same, but offset 8 hours to align with each respective timezone:

QUERY
IMAGE

QUERY
IMAGE
    </Step>
</Steps>

Before this lesson, all our time control mechanisms were based on relative times from now. With the lessons today, we have learned how to adjust the view depending where someone is in the world. Maybe a customer in East Coast America reports an issue and your engineering team is in West Coast America. They can build a dashboard and translate the view to map to the timezone as a customer would be citing. So if a customer advises an issue at 9am East Coast, we can ensure when we look at 9am we don't have to mentally translate.

Epoch and standard date stamps make sense. So when you need to focus your data to specific dates of an incident for example, and you want to investigate the data without a moving time window being relative to the current time, this knowledge will help you obtain data in a static time window.

### Using time-based cohorting

<Steps>
    <Step>
Time-based cohorting...what a complicated but fun term! While it sounds complex, "time-based cohorting" is simply a way to organize data into time-based groups like minuteOf, hourOf, weekOf, and more.

When we use the SINCE clause for durations, we retrieve the entire length of time queried for. But that data may not always tell the whole story! We may need to ananlyze performance within a time period more closely. With time-based cohorting, we can further sort the data into logical, time-based groupings.

Using a combination of FACET and one of the many time-based functions (such as hourOf(timestamp)) we can take a week’s worth of data and understand performance based on the specific hour it occurred. This reveals trends and identifies the most critical times for our application. Check it out:

QUERY
IMAGE
    </Step>
    <Step>
After running the query above we can see the slowest response time based on the hour of the day. Super interesting, right?

New Relic provides many different options to facet based on time. The previous example is grouped by the hour, but we can also group by the day of the week to determine which days have the best and worst response times.

QUERY
IMAGE
    </Step>
    <Step>
Now can see when are we slowest on any specific day. This could be logically extended to answer business-critical questions like "When do we sell the most products?", or "When do we have the most sign-ups or logins?".

You can also group results by a specific date. This helps when considering SLA reports, or analyzing performance changes over a given period.

QUERY
IMAGE        
    </Step>
</Steps>

Digging into your data is always fun! Time-based cohorting is an easy way to expose problems that occur on specific minutes, hours, days, or weeks. No matter what data you send to New Relic, NRQL allows you to slice, dice, organize, and visualize it however you want.

There are also many other options available to group by, including week, month, and year depending on your data retention. To see the full list, head to our [Group Results Across Time documentation Page](/docs/query-data/nrql-new-relic-query-language/nrql-query-examples/group-results-across-time).

<CollapserGroup>
    <Collapser
        id="summary"
        title="Lesson summary"
    >
With the knowledge you've gained here, you can create dashboard visualizations, and control the aspects of your data you're most interested in. These techniques are also extremely useful in narrowing focus for more granular, specific alerts!

You are now a Level 2 NRQL hero. You've learned great techniques to control your data and produce much more interesting visualizations. Get ready to advance to level three, where you'll learn more interesting NRQL skills including filters, facet cases, histogram, apdex, filtering to eventTypes, overriding values, and extrapolation.

Revel in your newly attained knowledge. You are now equipped to build really powerful dashboards and alerts that could be critical to your organization.
    </Collapser>
</CollapserGroup>

### What's next?

Content forthcoming